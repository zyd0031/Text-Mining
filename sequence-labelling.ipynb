{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:35.395200Z",
     "iopub.status.busy": "2023-11-07T13:53:35.394864Z",
     "iopub.status.idle": "2023-11-07T13:53:35.843569Z",
     "shell.execute_reply": "2023-11-07T13:53:35.842455Z",
     "shell.execute_reply.started": "2023-11-07T13:53:35.395173Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import csv\n",
    "import string\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import emoji\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:35.846403Z",
     "iopub.status.busy": "2023-11-07T13:53:35.845855Z",
     "iopub.status.idle": "2023-11-07T13:53:35.854560Z",
     "shell.execute_reply": "2023-11-07T13:53:35.853318Z",
     "shell.execute_reply.started": "2023-11-07T13:53:35.846364Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_file_as_lists(filename, delimiter='\\t'):\n",
    "    with open(filename) as stream:\n",
    "        reader = csv.reader(stream, delimiter=delimiter, quoting=csv.QUOTE_NONE)\n",
    "        labeled_tokens = [zip(*g) for k, g in groupby(reader, lambda x: not [s for s in x if s.strip()]) if not k]\n",
    "        tokens, labels = zip(*labeled_tokens)\n",
    "        return [list(t) for t in tokens], [list(l) for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:35.856338Z",
     "iopub.status.busy": "2023-11-07T13:53:35.855977Z",
     "iopub.status.idle": "2023-11-07T13:53:36.216711Z",
     "shell.execute_reply": "2023-11-07T13:53:36.215578Z",
     "shell.execute_reply.started": "2023-11-07T13:53:35.856304Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tokens, train_labels = read_file_as_lists(\"/kaggle/input/w-net-data/wnut17train.conll\")\n",
    "dev_tokens, dev_labels = read_file_as_lists(\"/kaggle/input/w-net-data/emerging.dev.conll\")\n",
    "test_tokens, test_labels = read_file_as_lists(\"/kaggle/input/w-net-data/emerging.test.annotated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:36.218451Z",
     "iopub.status.busy": "2023-11-07T13:53:36.218122Z",
     "iopub.status.idle": "2023-11-07T13:53:36.224908Z",
     "shell.execute_reply": "2023-11-07T13:53:36.223851Z",
     "shell.execute_reply.started": "2023-11-07T13:53:36.218416Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_tokens(token_list):\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "#     spell = Speller(lang='en')\n",
    "    for tokens in token_list:\n",
    "        for i in range(len(tokens)):\n",
    "            if re.match(url_pattern, tokens[i]):\n",
    "                tokens[i] = '<URL>' \n",
    "            elif emoji.emoji_count(tokens[i]) > 0:\n",
    "                tokens[i] = '<emoji>'\n",
    "#             else:\n",
    "#                 tokens[i] = spell(tokens[i])\n",
    "        \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:36.228890Z",
     "iopub.status.busy": "2023-11-07T13:53:36.228466Z",
     "iopub.status.idle": "2023-11-07T13:53:37.541811Z",
     "shell.execute_reply": "2023-11-07T13:53:37.540750Z",
     "shell.execute_reply.started": "2023-11-07T13:53:36.228861Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tokens = clean_tokens(train_tokens)\n",
    "dev_tokens = clean_tokens(dev_tokens)\n",
    "test_tokens = clean_tokens(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:37.543816Z",
     "iopub.status.busy": "2023-11-07T13:53:37.543414Z",
     "iopub.status.idle": "2023-11-07T13:53:37.556030Z",
     "shell.execute_reply": "2023-11-07T13:53:37.554769Z",
     "shell.execute_reply.started": "2023-11-07T13:53:37.543781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "3394\n",
      "**************************************************\n",
      "Dev\n",
      "1009\n",
      "**************************************************\n",
      "Test\n",
      "1287\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "print(len(train_tokens))\n",
    "print('*'*50)\n",
    "print(\"Dev\")\n",
    "print(len(dev_tokens))\n",
    "print('*'*50)\n",
    "print(\"Test\")\n",
    "print(len(test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:37.558167Z",
     "iopub.status.busy": "2023-11-07T13:53:37.557650Z",
     "iopub.status.idle": "2023-11-07T13:53:37.574025Z",
     "shell.execute_reply": "2023-11-07T13:53:37.572836Z",
     "shell.execute_reply.started": "2023-11-07T13:53:37.558109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "62730\n",
      "**************************************************\n",
      "Dev\n",
      "15733\n",
      "**************************************************\n",
      "Test\n",
      "23394\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "print(len([token for sublist in train_tokens for token in sublist]))\n",
    "print('*'*50)\n",
    "print(\"Dev\")\n",
    "print(len([token for sublist in dev_tokens for token in sublist]))\n",
    "print('*'*50)\n",
    "print(\"Test\")\n",
    "print(len([token for sublist in test_tokens for token in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:37.576536Z",
     "iopub.status.busy": "2023-11-07T13:53:37.575821Z",
     "iopub.status.idle": "2023-11-07T13:53:37.598162Z",
     "shell.execute_reply": "2023-11-07T13:53:37.596906Z",
     "shell.execute_reply.started": "2023-11-07T13:53:37.576497Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_entities = pd.DataFrame({\"train_entities\": [entity for sublist in train_labels for entity in sublist if entity != 'O']})\n",
    "df_dev_entities = pd.DataFrame({\"dev_entities\": [entity for sublist in dev_labels for entity in sublist if entity != 'O']})\n",
    "df_test_entities = pd.DataFrame({\"test_entities\": [entity for sublist in test_labels for entity in sublist if entity != 'O']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:37.600022Z",
     "iopub.status.busy": "2023-11-07T13:53:37.599413Z",
     "iopub.status.idle": "2023-11-07T13:53:37.632066Z",
     "shell.execute_reply": "2023-11-07T13:53:37.630697Z",
     "shell.execute_reply.started": "2023-11-07T13:53:37.599992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_entities_count: 3160\n",
      "df_dev_entities_count: 1250\n",
      "df_test_entities_count: 1740\n"
     ]
    }
   ],
   "source": [
    "df_train_entities_count = df_train_entities[\"train_entities\"].value_counts().sum()\n",
    "df_dev_entities_count = df_dev_entities[\"dev_entities\"].value_counts().sum()\n",
    "df_test_entities_count = df_test_entities[\"test_entities\"].value_counts().sum()\n",
    "print(f\"df_train_entities_count: {df_train_entities_count}\")\n",
    "print(f\"df_dev_entities_count: {df_dev_entities_count}\")\n",
    "print(f\"df_test_entities_count: {df_test_entities_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:37.634183Z",
     "iopub.status.busy": "2023-11-07T13:53:37.633422Z",
     "iopub.status.idle": "2023-11-07T13:53:37.677082Z",
     "shell.execute_reply": "2023-11-07T13:53:37.675857Z",
     "shell.execute_reply.started": "2023-11-07T13:53:37.634146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_entities\n",
      "person: 995\n",
      "location: 793\n",
      "corporation: 267\n",
      "product: 345\n",
      "creative-work: 346\n",
      "group: 414\n",
      "**************************************************\n",
      "dev_entities\n",
      "person: 587\n",
      "location: 107\n",
      "corporation: 46\n",
      "product: 208\n",
      "creative-work: 238\n",
      "group: 64\n",
      "**************************************************\n",
      "test_entities\n",
      "person: 560\n",
      "location: 244\n",
      "corporation: 88\n",
      "product: 253\n",
      "creative-work: 360\n",
      "group: 235\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "types = [\"person\", \"location\", \"corporation\", \"product\", \"creative-work\", \"group\"]\n",
    "for data in [df_train_entities, df_dev_entities, df_test_entities]:\n",
    "    print(data.columns[0])\n",
    "    for type_ in types:\n",
    "        print(f\"{type_}: {data[data.columns[0]].str.endswith(type_).sum()}\")\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:37.680242Z",
     "iopub.status.busy": "2023-11-07T13:53:37.679528Z",
     "iopub.status.idle": "2023-11-07T13:53:37.701045Z",
     "shell.execute_reply": "2023-11-07T13:53:37.698238Z",
     "shell.execute_reply.started": "2023-11-07T13:53:37.680171Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_label2index(data):\n",
    "    labels = list(set([label for sublist in data for label in sublist]))\n",
    "    index2label = dict(enumerate(labels))\n",
    "    label2index = {value: key for key, value in index2label.items()}\n",
    "    return label2index\n",
    "\n",
    "label2index = get_label2index(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:37.703985Z",
     "iopub.status.busy": "2023-11-07T13:53:37.703110Z",
     "iopub.status.idle": "2023-11-07T13:53:37.714325Z",
     "shell.execute_reply": "2023-11-07T13:53:37.713344Z",
     "shell.execute_reply.started": "2023-11-07T13:53:37.703947Z"
    }
   },
   "outputs": [],
   "source": [
    "index2label = {value: key for key, value in label2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:37.716689Z",
     "iopub.status.busy": "2023-11-07T13:53:37.715964Z",
     "iopub.status.idle": "2023-11-07T13:53:37.749291Z",
     "shell.execute_reply": "2023-11-07T13:53:37.748152Z",
     "shell.execute_reply.started": "2023-11-07T13:53:37.716611Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = [[label2index.get(i) for i in sublist] for sublist in train_labels]\n",
    "dev_labels = [[label2index.get(i) for i in sublist] for sublist in dev_labels]\n",
    "test_labels = [[label2index.get(i) for i in sublist] for sublist in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:37.755778Z",
     "iopub.status.busy": "2023-11-07T13:53:37.755436Z",
     "iopub.status.idle": "2023-11-07T13:53:39.020797Z",
     "shell.execute_reply": "2023-11-07T13:53:39.019600Z",
     "shell.execute_reply.started": "2023-11-07T13:53:37.755750Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_data = Dataset.from_dict({'tokens': train_tokens, 'labels': train_labels})\n",
    "dev_data = Dataset.from_dict({'tokens': dev_tokens, 'labels': dev_labels})\n",
    "test_data = Dataset.from_dict({'tokens': test_tokens, 'labels': test_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:39.022672Z",
     "iopub.status.busy": "2023-11-07T13:53:39.022069Z",
     "iopub.status.idle": "2023-11-07T13:53:39.028115Z",
     "shell.execute_reply": "2023-11-07T13:53:39.026928Z",
     "shell.execute_reply.started": "2023-11-07T13:53:39.022614Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_data,\n",
    "    'dev': dev_data,\n",
    "    'test': test_data\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:39.030359Z",
     "iopub.status.busy": "2023-11-07T13:53:39.029830Z",
     "iopub.status.idle": "2023-11-07T13:53:41.719940Z",
     "shell.execute_reply": "2023-11-07T13:53:41.719073Z",
     "shell.execute_reply.started": "2023-11-07T13:53:39.030314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564c8addf3be4a01a774923fb162e45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1658ab34dcde47aba5a027538e938c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ab50c05a4f4654abecbeb720f36c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efd0ea0a8b447ee8291fe18d2eb4d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:41.721524Z",
     "iopub.status.busy": "2023-11-07T13:53:41.721087Z",
     "iopub.status.idle": "2023-11-07T13:53:41.726868Z",
     "shell.execute_reply": "2023-11-07T13:53:41.725676Z",
     "shell.execute_reply.started": "2023-11-07T13:53:41.721498Z"
    }
   },
   "outputs": [],
   "source": [
    "B2I = {\n",
    "    2:10,\n",
    "    4:0,\n",
    "    5:8,\n",
    "    6:1,\n",
    "    7:12,\n",
    "    11:9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:41.729131Z",
     "iopub.status.busy": "2023-11-07T13:53:41.728741Z",
     "iopub.status.idle": "2023-11-07T13:53:41.739531Z",
     "shell.execute_reply": "2023-11-07T13:53:41.738518Z",
     "shell.execute_reply.started": "2023-11-07T13:53:41.729101Z"
    }
   },
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            label = labels[word_id]\n",
    "            if label in B2I.keys():\n",
    "                label = B2I.get(label)\n",
    "            new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:41.741224Z",
     "iopub.status.busy": "2023-11-07T13:53:41.740922Z",
     "iopub.status.idle": "2023-11-07T13:53:41.750401Z",
     "shell.execute_reply": "2023-11-07T13:53:41.749352Z",
     "shell.execute_reply.started": "2023-11-07T13:53:41.741199Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"labels\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:41.752268Z",
     "iopub.status.busy": "2023-11-07T13:53:41.751836Z",
     "iopub.status.idle": "2023-11-07T13:53:42.834296Z",
     "shell.execute_reply": "2023-11-07T13:53:42.833243Z",
     "shell.execute_reply.started": "2023-11-07T13:53:41.752233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4723a17a2d5a407ab34a715341817838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1718b6b61446d0b781d28ddaf1ca74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f02254e969f4ae6be942cb1077b0fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:42.835973Z",
     "iopub.status.busy": "2023-11-07T13:53:42.835678Z",
     "iopub.status.idle": "2023-11-07T13:53:54.041985Z",
     "shell.execute_reply": "2023-11-07T13:53:54.041055Z",
     "shell.execute_reply.started": "2023-11-07T13:53:42.835949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:54.043794Z",
     "iopub.status.busy": "2023-11-07T13:53:54.043193Z",
     "iopub.status.idle": "2023-11-07T13:53:56.972981Z",
     "shell.execute_reply": "2023-11-07T13:53:56.972087Z",
     "shell.execute_reply.started": "2023-11-07T13:53:54.043766Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "train = data_collator(tokenized_datasets[\"train\"])\n",
    "dev = data_collator(tokenized_datasets[\"dev\"])\n",
    "test = data_collator(tokenized_datasets[\"test\"])                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:53:56.974799Z",
     "iopub.status.busy": "2023-11-07T13:53:56.974182Z",
     "iopub.status.idle": "2023-11-07T13:54:13.660194Z",
     "shell.execute_reply": "2023-11-07T13:54:13.659067Z",
     "shell.execute_reply.started": "2023-11-07T13:53:56.974763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=b0f8874baa4bce47abe940307214b6293c650b54a512af2b174bde3c6d04c974\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:54:13.661989Z",
     "iopub.status.busy": "2023-11-07T13:54:13.661634Z",
     "iopub.status.idle": "2023-11-07T13:54:26.230211Z",
     "shell.execute_reply": "2023-11-07T13:54:26.228943Z",
     "shell.execute_reply.started": "2023-11-07T13:54:13.661950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:54:26.232425Z",
     "iopub.status.busy": "2023-11-07T13:54:26.232008Z",
     "iopub.status.idle": "2023-11-07T13:54:29.325686Z",
     "shell.execute_reply": "2023-11-07T13:54:29.324780Z",
     "shell.execute_reply.started": "2023-11-07T13:54:26.232384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2d48a1253143bba98640f546827d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:54:29.327076Z",
     "iopub.status.busy": "2023-11-07T13:54:29.326787Z",
     "iopub.status.idle": "2023-11-07T13:54:29.335362Z",
     "shell.execute_reply": "2023-11-07T13:54:29.334188Z",
     "shell.execute_reply.started": "2023-11-07T13:54:29.327050Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[index2label.get(l) for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [index2label.get(p) for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:54:29.337093Z",
     "iopub.status.busy": "2023-11-07T13:54:29.336784Z",
     "iopub.status.idle": "2023-11-07T13:54:33.131106Z",
     "shell.execute_reply": "2023-11-07T13:54:33.130314Z",
     "shell.execute_reply.started": "2023-11-07T13:54:29.337056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d29db36cca2454cb2be35ade1ce9e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=index2label,\n",
    "    label2id=label2index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:54:33.132746Z",
     "iopub.status.busy": "2023-11-07T13:54:33.132377Z",
     "iopub.status.idle": "2023-11-07T13:54:33.211499Z",
     "shell.execute_reply": "2023-11-07T13:54:33.210573Z",
     "shell.execute_reply.started": "2023-11-07T13:54:33.132713Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:54:33.213052Z",
     "iopub.status.busy": "2023-11-07T13:54:33.212741Z",
     "iopub.status.idle": "2023-11-07T13:59:19.030680Z",
     "shell.execute_reply": "2023-11-07T13:59:19.029673Z",
     "shell.execute_reply.started": "2023-11-07T13:54:33.213026Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20231107_135601-roimbntl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/abb382937/huggingface/runs/roimbntl' target=\"_blank\">eager-spaceship-5</a></strong> to <a href='https://wandb.ai/abb382937/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/abb382937/huggingface' target=\"_blank\">https://wandb.ai/abb382937/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/abb382937/huggingface/runs/roimbntl' target=\"_blank\">https://wandb.ai/abb382937/huggingface/runs/roimbntl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='639' max='639' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [639/639 02:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.370723</td>\n",
       "      <td>0.599493</td>\n",
       "      <td>0.277582</td>\n",
       "      <td>0.379462</td>\n",
       "      <td>0.912219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.390677</td>\n",
       "      <td>0.630662</td>\n",
       "      <td>0.318662</td>\n",
       "      <td>0.423392</td>\n",
       "      <td>0.917312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>0.364942</td>\n",
       "      <td>0.609971</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.457646</td>\n",
       "      <td>0.921834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=639, training_loss=0.17325312654737016, metrics={'train_runtime': 279.4317, 'train_samples_per_second': 36.438, 'train_steps_per_second': 2.287, 'total_flos': 287048741860728.0, 'train_loss': 0.17325312654737016, 'epoch': 3.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"dev\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:59:19.032275Z",
     "iopub.status.busy": "2023-11-07T13:59:19.031987Z",
     "iopub.status.idle": "2023-11-07T13:59:26.077376Z",
     "shell.execute_reply": "2023-11-07T13:59:26.076379Z",
     "shell.execute_reply.started": "2023-11-07T13:59:19.032249Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [81/81 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5096039772033691,\n",
       " 'eval_precision': 0.5683673469387756,\n",
       " 'eval_recall': 0.21514098107377366,\n",
       " 'eval_f1': 0.31213224992995237,\n",
       " 'eval_accuracy': 0.9145766485495384,\n",
       " 'eval_runtime': 7.0325,\n",
       " 'eval_samples_per_second': 183.007,\n",
       " 'eval_steps_per_second': 11.518,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:59:26.078967Z",
     "iopub.status.busy": "2023-11-07T13:59:26.078643Z",
     "iopub.status.idle": "2023-11-07T13:59:26.086128Z",
     "shell.execute_reply": "2023-11-07T13:59:26.085261Z",
     "shell.execute_reply.started": "2023-11-07T13:59:26.078940Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    true_labels = [[index2label.get(l) for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [index2label.get(p) for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:59:26.087747Z",
     "iopub.status.busy": "2023-11-07T13:59:26.087454Z",
     "iopub.status.idle": "2023-11-07T13:59:26.105247Z",
     "shell.execute_reply": "2023-11-07T13:59:26.104265Z",
     "shell.execute_reply.started": "2023-11-07T13:59:26.087723Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from accelerate import Accelerator\n",
    "from transformers import get_scheduler\n",
    "from accelerate import Accelerator\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def Training(lr, batch_size):\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        tokenized_datasets[\"train\"],\n",
    "        shuffle=True,\n",
    "        collate_fn=data_collator,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    eval_dataloader = DataLoader(\n",
    "        tokenized_datasets[\"dev\"], collate_fn=data_collator, batch_size=batch_size\n",
    "    )\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_checkpoint,\n",
    "        id2label=index2label,\n",
    "        label2id=label2index,\n",
    "    )\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    accelerator = Accelerator()\n",
    "    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, eval_dataloader\n",
    "    )\n",
    "    num_train_epochs = 3\n",
    "    num_update_steps_per_epoch = len(train_dataloader)\n",
    "    num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "    accelerator = Accelerator()\n",
    "    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, eval_dataloader\n",
    "    )\n",
    "    \n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    for epoch in range(num_train_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            accelerator.backward(loss)\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        for batch in eval_dataloader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "            labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "            predictions_gathered = accelerator.gather(predictions)\n",
    "            labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "            true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "            metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "        results = metric.compute()\n",
    "        print(\n",
    "            f\"epoch {epoch}:\",\n",
    "            {\n",
    "                key: results[f\"overall_{key}\"]\n",
    "                for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T13:59:26.107247Z",
     "iopub.status.busy": "2023-11-07T13:59:26.106301Z",
     "iopub.status.idle": "2023-11-07T14:13:39.325064Z",
     "shell.execute_reply": "2023-11-07T14:13:39.323504Z",
     "shell.execute_reply.started": "2023-11-07T13:59:26.107214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate:0.0001\n",
      "batch_size:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7139968c8a6c483f9aa76577071996c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.1068075117370892, 'recall': 0.5112359550561798, 'f1': 0.1766990291262136, 'accuracy': 0.8971986902967621}\n",
      "epoch 1: {'precision': 0.3163145539906103, 'recall': 0.6814159292035398, 'f1': 0.432064128256513, 'accuracy': 0.916012681253573}\n",
      "epoch 2: {'precision': 0.3227699530516432, 'recall': 0.5623721881390593, 'f1': 0.4101416853094705, 'accuracy': 0.9170001559170521}\n",
      "\n",
      "\n",
      "learning rate:0.0001\n",
      "batch_size:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4485a18e824d84956fa85422036cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.14847417840375587, 'recall': 0.6200980392156863, 'f1': 0.23958333333333334, 'accuracy': 0.901616340107063}\n",
      "epoch 1: {'precision': 0.29988262910798125, 'recall': 0.53732912723449, 'f1': 0.3849340866290019, 'accuracy': 0.9152330959929318}\n",
      "epoch 2: {'precision': 0.33098591549295775, 'recall': 0.6064516129032258, 'f1': 0.428246013667426, 'accuracy': 0.9199106075567798}\n",
      "\n",
      "\n",
      "learning rate:5e-05\n",
      "batch_size:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa4e476707b46b6adbe81f9ad5890d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.25997652582159625, 'recall': 0.6257062146892656, 'f1': 0.3673300165837479, 'accuracy': 0.913050257263136}\n",
      "epoch 1: {'precision': 0.3685446009389671, 'recall': 0.6603575184016824, 'f1': 0.4730696798493409, 'accuracy': 0.922405280390832}\n",
      "epoch 2: {'precision': 0.3926056338028169, 'recall': 0.6482558139534884, 'f1': 0.48903508771929816, 'accuracy': 0.9248999532248844}\n",
      "\n",
      "\n",
      "learning rate:5e-05\n",
      "batch_size:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d72353881624819b9b64cb75fedeaf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.23591549295774647, 'recall': 0.6860068259385665, 'f1': 0.35109170305676857, 'accuracy': 0.9101398056234083}\n",
      "epoch 1: {'precision': 0.3397887323943662, 'recall': 0.6624713958810069, 'f1': 0.44918541505042664, 'accuracy': 0.9210539992723871}\n",
      "epoch 2: {'precision': 0.3955399061032864, 'recall': 0.5980479148181012, 'f1': 0.4761568350406217, 'accuracy': 0.924120367964243}\n",
      "\n",
      "\n",
      "learning rate:1e-05\n",
      "batch_size:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b86eea8bcc6480b8cb64d83994dde01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.13791079812206572, 'recall': 0.5745721271393643, 'f1': 0.22243256034074774, 'accuracy': 0.9006808377942934}\n",
      "epoch 1: {'precision': 0.272887323943662, 'recall': 0.6094364351245085, 'f1': 0.3769760843129307, 'accuracy': 0.9135699807702302}\n",
      "epoch 2: {'precision': 0.3380281690140845, 'recall': 0.5702970297029702, 'f1': 0.42446573323507736, 'accuracy': 0.9186632711397537}\n",
      "\n",
      "\n",
      "learning rate:1e-05\n",
      "batch_size:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b338fac8c5ff43c0b55791b714830679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/639 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.004694835680751174, 'recall': 0.42105263157894735, 'f1': 0.009286128845037725, 'accuracy': 0.8876357777662284}\n",
      "epoch 1: {'precision': 0.2282863849765258, 'recall': 0.5966257668711656, 'f1': 0.33022071307300516, 'accuracy': 0.9084766904007068}\n",
      "epoch 2: {'precision': 0.2494131455399061, 'recall': 0.5577427821522309, 'f1': 0.3446877534468775, 'accuracy': 0.9099319162205707}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-4, 5e-5, 1e-5]\n",
    "batch_sizes = [8, 16]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"learning rate:{learning_rate}\")\n",
    "        print(f\"batch_size:{batch_size}\")\n",
    "        Training(lr = learning_rate, batch_size = batch_size)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T14:13:39.326768Z",
     "iopub.status.busy": "2023-11-07T14:13:39.326424Z",
     "iopub.status.idle": "2023-11-07T14:16:03.918861Z",
     "shell.execute_reply": "2023-11-07T14:16:03.917670Z",
     "shell.execute_reply.started": "2023-11-07T14:13:39.326740Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688b79b977094163ba79d4787bdd484f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 5e-5\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"dev\"], collate_fn=data_collator, batch_size=batch_size\n",
    ")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=index2label,\n",
    "    label2id=label2index,\n",
    ")\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T14:25:23.584055Z",
     "iopub.status.busy": "2023-11-07T14:25:23.583638Z",
     "iopub.status.idle": "2023-11-07T14:25:28.484862Z",
     "shell.execute_reply": "2023-11-07T14:25:28.483705Z",
     "shell.execute_reply.started": "2023-11-07T14:25:23.584026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "true_predictions_list = []\n",
    "true_labels_list = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=batch_size\n",
    ")\n",
    "device = \"cuda:0\"\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        model.to(device)  \n",
    "        batch = {key: value.to(device) for key, value in batch.items()}  \n",
    "\n",
    "        outputs = model(**batch)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "\n",
    "        true_predictions_list.append(true_predictions)\n",
    "        true_labels_list.append(true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T14:36:03.211164Z",
     "iopub.status.busy": "2023-11-07T14:36:03.210777Z",
     "iopub.status.idle": "2023-11-07T14:36:03.218038Z",
     "shell.execute_reply": "2023-11-07T14:36:03.216763Z",
     "shell.execute_reply.started": "2023-11-07T14:36:03.211133Z"
    }
   },
   "outputs": [],
   "source": [
    "true_labels = [subsublist for sublist in true_labels_list for subsublist in sublist]\n",
    "true_predictions = [subsublist for sublist in true_predictions for subsublist in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T14:37:06.732427Z",
     "iopub.status.busy": "2023-11-07T14:37:06.732037Z",
     "iopub.status.idle": "2023-11-07T14:37:07.191910Z",
     "shell.execute_reply": "2023-11-07T14:37:07.189911Z",
     "shell.execute_reply.started": "2023-11-07T14:37:06.732393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.22556971803785245\n",
      "Recall: 0.5719882468168462\n",
      "F1-score: 0.3235457063711911\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(true_labels, true_predictions)\n",
    "\n",
    "recall = recall_score(true_labels, true_predictions)\n",
    "\n",
    "f1 = f1_score(true_labels, true_predictions)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T14:16:08.723299Z",
     "iopub.status.busy": "2023-11-07T14:16:08.722903Z",
     "iopub.status.idle": "2023-11-07T14:16:08.732924Z",
     "shell.execute_reply": "2023-11-07T14:16:08.731656Z",
     "shell.execute_reply.started": "2023-11-07T14:16:08.723263Z"
    }
   },
   "outputs": [],
   "source": [
    "true_predictions_list = [item for sublist in true_predictions_list for subsublist in sublist for item in subsublist]\n",
    "true_labels_list = [item for sublist in true_labels_list for subsublist in sublist for item in subsublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T14:16:08.734463Z",
     "iopub.status.busy": "2023-11-07T14:16:08.734141Z",
     "iopub.status.idle": "2023-11-07T14:16:09.264453Z",
     "shell.execute_reply": "2023-11-07T14:16:09.263247Z",
     "shell.execute_reply.started": "2023-11-07T14:16:08.734425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       0.15      0.21      0.18       123\n",
      "B-creative-work       0.15      0.62      0.24       120\n",
      "        B-group       0.19      0.51      0.28        63\n",
      "     B-location       0.39      0.73      0.51       214\n",
      "       B-person       0.28      0.81      0.42       382\n",
      "      B-product       0.14      0.45      0.22        40\n",
      "  I-corporation       0.09      0.36      0.14        14\n",
      "I-creative-work       0.13      0.72      0.22        40\n",
      "        I-group       0.16      0.52      0.24        21\n",
      "     I-location       0.26      0.63      0.36        38\n",
      "       I-person       0.45      0.87      0.59        68\n",
      "      I-product       0.17      0.45      0.25        88\n",
      "              O       1.00      0.93      0.96     29331\n",
      "\n",
      "       accuracy                           0.91     30542\n",
      "      macro avg       0.27      0.60      0.36     30542\n",
      "   weighted avg       0.97      0.91      0.94     30542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels_list, true_predictions_list)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T14:16:09.266080Z",
     "iopub.status.busy": "2023-11-07T14:16:09.265780Z",
     "iopub.status.idle": "2023-11-07T14:16:09.695064Z",
     "shell.execute_reply": "2023-11-07T14:16:09.693971Z",
     "shell.execute_reply.started": "2023-11-07T14:16:09.266054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_f1:0.9149040665313339\n",
      "macro_f1:0.3552110131759258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "micro_f1 = f1_score(true_labels_list, true_predictions_list, average='micro')\n",
    "macro_f1 = f1_score(true_labels_list, true_predictions_list, average='macro')\n",
    "print(f\"micro_f1:{micro_f1}\")\n",
    "print(f\"macro_f1:{macro_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T14:16:09.697945Z",
     "iopub.status.busy": "2023-11-07T14:16:09.696493Z",
     "iopub.status.idle": "2023-11-07T14:16:10.210793Z",
     "shell.execute_reply": "2023-11-07T14:16:10.209501Z",
     "shell.execute_reply.started": "2023-11-07T14:16:09.697904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "            O       1.00      0.93      0.96     29331\n",
      "  corporation       0.16      0.26      0.20       137\n",
      "creative-work       0.16      0.70      0.26       160\n",
      "        group       0.19      0.52      0.28        84\n",
      "     location       0.39      0.77      0.52       252\n",
      "       person       0.31      0.84      0.45       450\n",
      "      product       0.17      0.48      0.25       128\n",
      "\n",
      "     accuracy                           0.92     30542\n",
      "    macro avg       0.34      0.64      0.42     30542\n",
      " weighted avg       0.97      0.92      0.94     30542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_true_labels = [label[2:] if len(label) >1 else label for label in true_labels_list] \n",
    "entity_prediction_labels = [label[2:] if len(label) >1 else label for label in true_predictions_list] \n",
    "\n",
    "report = classification_report(entity_true_labels, entity_prediction_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T14:16:10.212510Z",
     "iopub.status.busy": "2023-11-07T14:16:10.212184Z",
     "iopub.status.idle": "2023-11-07T14:16:10.644705Z",
     "shell.execute_reply": "2023-11-07T14:16:10.642797Z",
     "shell.execute_reply.started": "2023-11-07T14:16:10.212482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro_f1:0.9162137384585162\n",
      "macro_f1:0.41537515841288536\n"
     ]
    }
   ],
   "source": [
    "micro_f1 = f1_score(entity_true_labels, entity_prediction_labels, average='micro')\n",
    "macro_f1 = f1_score(entity_true_labels, entity_prediction_labels, average='macro')\n",
    "print(f\"micro_f1:{micro_f1}\")\n",
    "print(f\"macro_f1:{macro_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3941726,
     "sourceId": 6857824,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3941835,
     "sourceId": 6858109,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
